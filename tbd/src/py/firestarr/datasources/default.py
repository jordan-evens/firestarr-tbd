import datetime
import os
from functools import cache

import datasources.spotwx
import numpy as np
import pandas as pd
from common import (
    DEFAULT_M3_UNMATCHED_LAST_ACTIVE_IN_DAYS,
    DIR_SRC_PY_FIRSTARR,
    listdir_sorted,
    logging,
    pick_max,
    pick_max_by_column,
    to_utc,
    tqdm_util,
)
from datasources.cwfis import SourceFeatureM3, SourceFireCiffc, SourceFwiCwfis
from datasources.datatypes import (
    SourceFeature,
    SourceFire,
    SourceFwi,
    SourceHourly,
    SourceModel,
    make_template_empty,
)
from gis import (
    CRS_COMPARISON,
    CRS_WGS84,
    KM_TO_M,
    area_ha,
    area_ha_to_radius_m,
    save_shp,
    to_gdf,
)

STATUS_RANK = ["OUT", "UC", "BH", "OC", "UNK"]


def wx_interpolate(df):
    date_min = df["datetime"].min()
    date_max = df["datetime"].max()
    times = pd.DataFrame(
        pd.date_range(date_min, date_max, freq="H").values, columns=["datetime"]
    )
    crs = df.crs
    index_names = df.index.names
    df = df.reset_index()
    idx_geom = ["lat", "lon", "geometry"]
    gdf_geom = df[idx_geom].drop_duplicates().reset_index(drop=True)
    del df["geometry"]
    groups = []
    for i, g in df.groupby(index_names):
        g_fill = pd.merge(times, g, how="left")
        # treat rain as if it all happened at start of any gaps
        g_fill["prec"] = g_fill["prec"].fillna(0)
        g_fill = g_fill.fillna(method="ffill")
        g_fill[index_names] = i
        groups.append(g_fill)
    df_filled = to_gdf(pd.merge(pd.concat(groups), gdf_geom), crs)
    df_filled.set_index(index_names)
    return df_filled


def find_rank(x):
    # rank is highest if unknown value
    return STATUS_RANK.index(x) if x in STATUS_RANK else (len(STATUS_RANK) - 1)


def assign_fires(
    origin,
    df_features,
    df_fires,
    days_to_keep_unmatched=DEFAULT_M3_UNMATCHED_LAST_ACTIVE_IN_DAYS,
):
    # do this to make an index column
    df_features = df_features.reset_index().to_crs(CRS_COMPARISON)
    df_fires = df_fires.reset_index().to_crs(CRS_COMPARISON)
    df_join = df_features.sjoin_nearest(df_fires, how="left", max_distance=1 * KM_TO_M)
    df_join["status_rank"] = tqdm_util.apply(
        df_join["status"], find_rank, desc="Ranking by status"
    )
    df_unmatched = df_join[df_join["fire_name"].isna()][
        ["datetime_left", "geometry"]
    ].rename(columns={"datetime_left": "datetime"})
    # HACK: if unmatched then ignore more readily based on age
    min_active = to_utc(origin.today - datetime.timedelta(days=days_to_keep_unmatched))
    df_unmatched = df_unmatched[df_unmatched["datetime"] >= min_active].reset_index(
        drop=True
    )
    df_join = df_join[~df_join["fire_name"].isna()]
    df_join = df_join.sort_values(
        ["index", "status_rank", "area", "fire_name"], ascending=False
    )
    # should mean only one copy of each geometry, and picked by fire with highest status
    df_first = df_join.groupby("index").first()
    # doesn't have crs after groupby
    df_first.crs = df_join.crs
    # want to keep all the fires that geometries intersect circles for
    # so that we can replace all of their named entries
    df_status = df_join.loc[:].set_index(["index"])
    # assign highest status for any of overlapping fires to all fires that overlap
    df_status[["status", "status_rank"]] = df_first.loc[df_status.index][
        ["status", "status_rank"]
    ]
    # dissolve by fire_name but use max so highest lastdate stays
    df_dissolve = df_status.dissolve(by="fire_name", aggfunc="max").reset_index()
    df_dissolve["datetime"] = pick_max(
        df_dissolve["datetime_left"], df_dissolve["datetime_right"]
    )
    # at this point we might have the same geometry for multiple fires, but that
    # just means they'll all get replaced with it and then the group dissolve
    # will take care of duplicates
    df_matched = df_dissolve[["fire_name", "datetime", "status", "geometry"]]
    df_features = df_matched.reset_index(drop=True)
    df_features["area"] = area_ha(df_features)
    df_unmatched["area"] = area_ha(df_unmatched)
    return (
        df_features.set_index(["fire_name"]).to_crs(CRS_WGS84),
        df_unmatched.to_crs(CRS_WGS84),
    )


def override_fires(df_fires, df_override):
    if df_override is not None and 0 < len(df_override):
        if df_fires.crs != df_override.crs:
            raise RuntimeError("Expected matching CRS for override_fires()")
        # override df_fires when they match
        matched = list(set(df_override.index).intersection(set(df_fires.index)))
        unmatched = list(set(df_override.index).difference(set(matched)))
        if unmatched:
            logging.warning(f"Ignoring unmatched fires:\n{df_override.loc[unmatched]}")
        df_fires = df_fires.loc[:]
        df_override = df_override.loc[:]
        cols_missing = [x for x in df_override.columns if np.all(df_override[x].isna())]
        if cols_missing:
            df_override.loc[matched, cols_missing] = df_fires.loc[matched, cols_missing]
        df_fires.loc[matched] = df_override.loc[matched]
        df_fires.loc[matched, "datetime"] = pick_max_by_column(
            df_fires, df_override, "datetime", matched
        )
    return df_fires


def find_sources_in_module(module, class_type):
    import importlib
    import inspect

    module = importlib.import_module(module)
    classes = [
        y for y in [getattr(module, x) for x in dir(module)] if inspect.isclass(y)
    ]
    return [
        c for c in classes if (issubclass(c, class_type) and not inspect.isabstract(c))
    ]


def find_sources(class_type, dir_search="private"):
    path = os.path.join(DIR_SRC_PY_FIRSTARR, "datasources", dir_search)
    if not os.path.isdir(path):
        return []
    files = [f.replace(".py", "") for f in listdir_sorted(path) if f.endswith(".py")]
    modules = [f"datasources.{dir_search.replace('/', '.')}.{f}" for f in files]
    from itertools import chain

    return list(
        chain.from_iterable([find_sources_in_module(m, class_type) for m in modules])
    )


class SourceFireActive(SourceFire):
    def __init__(
        self,
        dir_out,
        origin,
        status_include=None,
        status_omit=["OUT"],
    ) -> None:
        super().__init__(bounds=None)
        self._dir_out = dir_out
        self._origin = origin
        self._status_include = status_include
        self._status_omit = status_omit
        self._source_ciffc = SourceFireCiffc(
            dir_out, status_ignore=None, year=self._origin.today.year
        )
        # sources for features that we don't have a fire attached to
        self._source_features = [
            SourceFeatureM3(self._dir_out, self._origin),
        ] + [s(self._dir_out) for s in find_sources(SourceFeature)]
        # sources for features that area associated with specific fires
        self._source_fires = [s(self._dir_out) for s in find_sources(SourceFire)]

    @cache
    def _get_fires(self):
        def save_fires(df, file_root):
            df_points = df[df.geometry.type == "Point"]
            df_polygons = df[df.geometry.type != "Point"]
            if 0 < len(df_points):
                save_shp(
                    df_points,
                    os.path.join(self._dir_out, f"{file_root}_points"),
                )
            if 0 < len(df_polygons):
                save_shp(
                    df_polygons,
                    os.path.join(self._dir_out, f"{file_root}_polygons"),
                )

        df_ciffc = self._source_ciffc.get_fires()
        df_fires = df_ciffc.loc[:]
        save_shp(df_fires, os.path.join(self._dir_out, "df_fires_ciffc"))
        df_circles = df_fires.loc[df_fires.geometry.type == "Point"].to_crs(
            CRS_COMPARISON
        )
        # HACK: put in circles of proper area so spatial join should hopefully
        # overlap actual polygons
        df_circles["geometry"] = tqdm_util.apply(
            df_circles,
            lambda x: x.geometry.buffer(
                max(0.1, area_ha_to_radius_m(max(0, x["area"])))
            ),
            desc="Converting points with area to circles",
        ).simplify(100)
        df_circles = df_circles.to_crs(CRS_WGS84)
        save_shp(df_circles, os.path.join(self._dir_out, "df_fires_circles"))
        df_fires = self.check_columns(df_circles.iloc[:])
        df_unmatched = None
        # override with each source in the order they appear
        for i, src in enumerate(self._source_features):
            df_src = src.get_features()
            save_fires(df_src, f"df_fires_from_feature_source_{i:02d}")
            df_src_fires, df_unmatched_cur = assign_fires(
                self._origin, df_src, df_fires
            )
            save_fires(df_src_fires, f"df_fires_assigned_feature_source_{i:02d}")
            save_fires(df_unmatched_cur, f"df_fires_umatched_feature_source_{i:02d}")
            df_unmatched = pd.concat([df_unmatched, df_unmatched_cur])
            df_fires = override_fires(df_fires, df_src_fires)
            save_fires(df_fires, f"df_fires_after_feature_source_{i:02d}")
        for i, src in enumerate(self._source_fires):
            df_src_fires = src.get_fires()
            save_fires(df_src, f"df_fires_from_fire_source_{i:02d}")
            df_fires = override_fires(df_fires, df_src_fires)
            save_fires(df_fires, f"df_fires_after_fire_source_{i:02d}")
        df_fires = df_fires.reset_index()
        logging.info(
            "Have %d polygons that are not tied to a fire",
            len(df_unmatched),
        )
        if self._status_include:
            df_fires = df_fires.loc[df_fires.status.isin(self._status_include)]
            logging.info(
                "Have %d features that are tied to %s fires",
                len(df_fires),
                self._status_include,
            )
        save_fires(df_fires, "df_fires_after_status_include")
        if self._status_omit:
            df_fires = df_fires.loc[~df_fires.status.isin(self._status_omit)]
            logging.info(
                "Have %d features that aren't tied to %s fires",
                len(df_fires),
                self._status_omit,
            )
        save_fires(df_fires, "df_fires_after_status_omit")
        # pretty sure U is unknown status
        df_unmatched["status"] = "U"
        df_unmatched["fire_name"] = [f"UNMATCHED_{x}" for x in df_unmatched.index]
        df_all = pd.concat([df_fires, df_unmatched])
        save_fires(df_fires, "df_fires_after_concat")
        return df_all


class SourceFwiBest(SourceFwi):
    def __init__(
        self,
        dir_out,
    ) -> None:
        super().__init__(bounds=None)
        self._dir_out = dir_out
        self._sources = [s(self._dir_out) for s in find_sources(SourceFwi)] + [
            SourceFwiCwfis(self._dir_out)
        ]

    @cache
    def _get_fwi(self, lat, lon, date):
        # find first fwi source that applies to this
        for src in self._sources:
            if src.applies_to(lat, lon):
                break
        return src._get_fwi(lat, lon, date)


class SourceModelAll(SourceModel):
    def __init__(self, dir_out) -> None:
        super().__init__(bounds=None)
        self._dir_out = dir_out
        self._sources = [datasources.spotwx.SourceGEPS(self._dir_out)] + [
            s(self._dir_out) for s in find_sources(SourceModel)
        ]

    def _get_wx_model(self, lat, lon):
        return pd.concat(
            [
                src._get_wx_model(lat, lon)
                for src in self._sources
                if src.applies_to(lat, lon)
            ]
        )


class SourceHourlyEmpty(SourceHourly):
    def __init__(self) -> None:
        super().__init__(bounds=None)

    def _get_wx_hourly(self, lat, lon, datetime_start, datetime_end=None):
        return make_template_empty("hourly")


class SourceHourlyBest(SourceHourly):
    def __init__(self, dir_out) -> None:
        super().__init__(bounds=None)
        self._dir_out = dir_out
        self._sources = [s(self._dir_out) for s in find_sources(SourceHourly)] + [
            # need some default hourly weather source
            SourceHourlyEmpty()
        ]

    @cache
    def _get_wx_hourly(self, lat, lon, datetime_start, datetime_end=None):
        # find first fwi source that applies to this
        for src in self._sources:
            if src.applies_to(lat, lon):
                break
        return src._get_wx_hourly(lat, lon, datetime_start, datetime_end)
